{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a commute prediction network, and visualizing learning!  \n",
    "<ul> latest version available from: https://github.com/miroenev/teach_DL , prerequisites:\n",
    "* Matplotlib, Numpy, MxNet, and <a href=\"https://github.com/K3D-tools/K3D-jupyter\">K3D</a> for realtime training 3D surface visualization\n",
    "\n",
    "A video walkthrough of this notebook is <a href='https://youtu.be/HgbGJn9yz30'> available on YouTube</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import k3d\n",
    "\n",
    "#set default figure size\n",
    "plt.rcParams['figure.figsize'] = [9.5, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the problem\n",
    "\n",
    "Lets try to predict commute duration from two observable independent variables: the time of day and the weather conditions.\n",
    "\n",
    "<img src='figures/commute.png' width='400'/>\n",
    "<img src='figures/target_distribution.PNG' width='1000'/>\n",
    "In this toy example we'll first take on the role of the 'traffic gods' and decree that commute duration is defined through a linear mixture of the two independent variables. Later we'll sample from the distribution defined by these variables and generate a training dataset. This sampling procedure will be analogous to keeping a journal of all of our commutes for some [ long ] period of time, where each log entry consists of a set of  \n",
    "* <b>X</b>: [ time-of-departure, weather-condition ], and the associated  \n",
    "* <b>Y</b>: [ commute-duration ].\n",
    "\n",
    "<img src='figures/x_y_mapping.PNG' width='900'/>\n",
    "\n",
    "Given such a journal [dataset], we'll split it into training (75%) and testing (25%) subsets which we'll use to train and evaulate our model respectively. Specifically, we'll build a neural network model whose weights are initially randomly initialized, but are trained/updated as we stream the training data through (via the backpropagation learning algorithm). Each update will get us closer to having a model that has learned the relationship between X and Y or ([ time-of-departure, weather-condition ] to [ commute-duration] ).\n",
    "\n",
    "<img src='figures/process.PNG' width='800'/>\n",
    "\n",
    "During the training process we'll try to visualize the network's behavior by asking it to predict all the entries in our logbook using its current parameters/weights. As the training process unfolds, you should be able to see how the network adapts itself to the target surface/function that we determined for the commute duration.\n",
    "\n",
    "<img src='figures/training_progress.PNG' width='700'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine underlying relationship\n",
    "We'll start by esablishing (as traffic gods) the relationships between:  \n",
    "* 1) the time a commute starts (time-of-departure variable) and commute-duration\n",
    "* 2) the weather when a commute is started (weather-condtion variable) and commute-duration\n",
    "\n",
    "Note that as data scientists we never get to see this function, but we try to learn it from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data coordinates\n",
    "xRange = [0,10]; \n",
    "yRange = [0,10]; numSteps = 100\n",
    "\n",
    "x, y = np.meshgrid( np.linspace(xRange[0], xRange[1], numSteps),\n",
    "                    np.linspace(yRange[0], yRange[1], numSteps), indexing='ij' )\n",
    "\n",
    "def normalize_domain (x):\n",
    "    x = x + np.abs(np.min(x))\n",
    "    x = x / (np.max(x) + .001)\n",
    "    return x\n",
    "    \n",
    "# define 1D relationships to target\n",
    "xComponent = np.sin( x ) * 4\n",
    "yComponent = np.exp( y / 4 )\n",
    "\n",
    "# define 2D joint distribution\n",
    "z = xComponent + yComponent\n",
    "z = normalize_domain(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot independent variables\n",
    "plt.figure( figsize = ( 7, 7) )\n",
    "plt.subplots_adjust( left = 0.1, right = 0.9, top = 0.9, bottom = 0.1, wspace = 0.2 )\n",
    "plt.subplot(2,1,1); plt.plot(normalize_domain(xComponent[:,0])); plt.xlabel('time-of-day'), plt.ylabel('commute duration')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,1,2); plt.plot(normalize_domain(yComponent[0,:])); plt.xlabel('weather [ severity ]'), plt.ylabel('commute duration')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "\n",
    "# plot target [dependent] variable\n",
    "plt.figure( figsize = (9, 9) )\n",
    "plt.subplots_adjust( left = 0.1, right = 0.9, top = 0.9, bottom = 0.1 )\n",
    "ax = plt.subplot(1,1,1, projection='3d');\n",
    "ax.plot_surface ( x[0::1], y[0::1], z[0::1], color = 'blue', alpha = 1, antialiased = False )\n",
    "ax.set_xlabel('time of day')\n",
    "ax.set_ylabel('severity of weather')\n",
    "ax.set_zlabel('commute length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate  dataset\n",
    "Lets generate a dataset by randomly sampling from the target distribution [ with some noise ]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSamples = 5000\n",
    "noiseScaling = 1/8.\n",
    "\n",
    "gpu_device=mx.gpu()\n",
    "\n",
    "shuffledDataIndsX = np.random.randint(x.shape[0], size=(NSamples,1))\n",
    "shuffledDataIndsY = np.random.randint(y.shape[0], size=(NSamples,1))\n",
    "\n",
    "trainData = np.zeros( ( NSamples, 2 ) )\n",
    "targetValues = np.zeros( (NSamples, 1 ))\n",
    "noiseAmount = noiseScaling * ( np.random.rand(NSamples) - .5 )\n",
    "\n",
    "for iSample in range (NSamples):\n",
    "    trainData[iSample, 0] = x[ shuffledDataIndsX[iSample], 0 ]\n",
    "    trainData[iSample, 1] = y[ 0, shuffledDataIndsY[iSample] ]    \n",
    "    targetValues[iSample] = z[ shuffledDataIndsX[iSample], shuffledDataIndsY[iSample] ] + noiseAmount[iSample]\n",
    "\n",
    "trainDataGPU = mx.nd.array(trainData, ctx=gpu_device)\n",
    "targetValuesGPU = mx.nd.array(targetValues, ctx=gpu_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot dataset samples (red dots) overlayed onto target distribution (blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3D_data (k3dPlot):\n",
    "    zScaling = 5\n",
    "\n",
    "    offset = np.hstack( ( np.ones((trainData.shape[0], 1)) * -5, \n",
    "                          np.ones((trainData.shape[0], 1)) + 4, \n",
    "                          np.zeros((trainData.shape[0], 1)) ) ) * np.abs(xRange[1]-xRange[0])\n",
    "\n",
    "    k3dPlot += k3d.points ( np.hstack( ( trainData, targetValues*zScaling) ) + offset, color=0xFF0000, point_size = .2, shader = 'flat' )\n",
    "    \n",
    "    k3dPlot += k3d.surface ( np.rot90(z,3)*zScaling, color=0x0055FF, \n",
    "                            xmin=np.min(trainData[:,0]+offset[::,0]), \n",
    "                            xmax=np.max(trainData[:,0]+offset[::,0]), \n",
    "                            ymin=np.min(trainData[:,1]+offset[::,1]), \n",
    "                            ymax=np.max(trainData[:,1]+offset[::,1]))\n",
    "    return zScaling, offset\n",
    "\n",
    "plot = k3d.plot()\n",
    "_, _ = plot_3D_data(plot)\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = trainDataGPU\n",
    "label = targetValuesGPU[:,0]\n",
    "\n",
    "trainIterator = mx.io.NDArrayIter( data = data, label = label, \n",
    "                                   data_name = 'data', \n",
    "                                   label_name = 'linearOutput_label', batch_size = 256)\n",
    "\n",
    "predictIterator = mx.io.NDArrayIter( data = data, label = label, \n",
    "                                     data_name = 'data', \n",
    "                                     label_name = 'linearOutput_label', batch_size = NSamples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "inputData = mx.sym.Variable('data')\n",
    "targetLabelVar = mx.sym.Variable('linearOutput_label') \n",
    "\n",
    "layer1 = mx.sym.FullyConnected( data = inputData, name = 'fc1', num_hidden = 5)\n",
    "layer1Activation = mx.sym.Activation( data = layer1, name = 'sig1', act_type = \"sigmoid\")\n",
    "\n",
    "layer2 = mx.sym.FullyConnected( data = layer1Activation, name='fc2', num_hidden = 27)\n",
    "layer2Activation = mx.sym.Activation( data = layer2, name='sig2', act_type = \"sigmoid\")\n",
    "\n",
    "layer3 = mx.sym.FullyConnected( data = layer2Activation, name='fc3', num_hidden = 20)\n",
    "layer3Activation = mx.sym.Activation( data = layer3, name='sig3', act_type = \"sigmoid\")\n",
    "\n",
    "layer4 = mx.sym.FullyConnected( data = layer3Activation, name = 'fc4', num_hidden = 40)\n",
    "layer4Activation = mx.sym.Activation( data = layer4, name = 'sig4', act_type = \"sigmoid\")\n",
    "\n",
    "output = mx.sym.FullyConnected( data = layer4Activation, name='output', num_hidden=1)\n",
    "\n",
    "loss = mx.sym.LinearRegressionOutput( data = output, label = targetLabelVar , name = 'linearOutput_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = mx.mod.Module(symbol = loss,\n",
    "                    context = mx.gpu(0),\n",
    "                    data_names = ['data'],\n",
    "                    label_names = ['linearOutput_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate memory given the input data and label shapes\n",
    "mod.bind( data_shapes = trainIterator.provide_data, label_shapes = trainIterator.provide_label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters by uniform random numbers\n",
    "mod.init_params( initializer = mx.init.Xavier(), force_init = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use adam optimizer\n",
    "mod.init_optimizer( optimizer = 'adam' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use root mean squared error as the metric\n",
    "metric = mx.metric.create( 'rmse' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mx.viz.plot_network( loss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "sys.path.append('utils')\n",
    "import nnViz_mxnet\n",
    "importlib.reload(nnViz_mxnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnViz_mxnet.visualize_model(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model structure [loosely] inspired by NVIDIA's new HQ ;]  \n",
    "http://c.ymcdn.com/sites/aiascv.org/resource/resmgr/meeting_images/2017/March/Nv2.jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model Loop [ no visualization ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters by uniform random numbers\n",
    "mod.init_params( initializer = mx.init.Xavier(), force_init = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "startTime = time.time()\n",
    "for epoch in range(300):\n",
    "    \n",
    "    trainIterator.reset()\n",
    "    metric.reset()\n",
    "    \n",
    "    for batch in trainIterator:\n",
    "        \n",
    "        mod.forward( batch, is_train = True )       # compute predictions\n",
    "        mod.update_metric( metric, batch.label )    # accumulate prediction accuracy\n",
    "        mod.backward()                              # compute gradients\n",
    "        mod.update()                                # update parameters\n",
    "    \n",
    "    print('Epoch %d, Training %s' % (epoch, metric.get()))\n",
    "elapsedTime = time.time() - startTime\n",
    "print(elapsedTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model + Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters by uniform random numbers\n",
    "mod.init_params( initializer = mx.init.Xavier(), force_init = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "NEpochs = 350\n",
    "displayUpdateInterval = 10\n",
    "\n",
    "\n",
    "currentNN = {}\n",
    "plotCount = 0\n",
    "\n",
    "xOffset = np.zeros( (trainData.shape[0], 1))\n",
    "yOffset = np.zeros( (trainData.shape[0], 1))\n",
    "zOffset = np.zeros( (trainData.shape[0], 1))\n",
    "\n",
    "xModifier = 1 * np.abs(xRange[1]-xRange[0])*1.2; yModifier = 0; zModifier = 0; \n",
    "plotCount = 0\n",
    "\n",
    "evalLoss = np.empty((NEpochs))\n",
    "evalLoss[:] = np.NaN\n",
    "\n",
    "predictIterator.reset()\n",
    "nextIterData = predictIterator.next()\n",
    "batchInputs = nextIterData.data[0].asnumpy()\n",
    "\n",
    "# 3D plot\n",
    "plot = k3d.plot()\n",
    "zScaling, offset = plot_3D_data(plot)\n",
    "plot.display()\n",
    "\n",
    "# train 5 epochs, i.e. going over the data iter one pass\n",
    "for iEpoch in range(NEpochs):\n",
    "    \n",
    "    trainIterator.reset()\n",
    "    metric.reset()\n",
    "    \n",
    "    for batch in trainIterator:\n",
    "        mod.forward( batch, is_train = True )     # compute predictions\n",
    "        mod.update_metric( metric, batch.label )  # accumulate prediction accuracy\n",
    "        mod.backward()                            # compute gradients\n",
    "        mod.update()                              # update parameters\n",
    "    \n",
    "    evalLoss[iEpoch] = metric.get()[1]\n",
    "    print('Epoch: %d, Training Loss: %s' % ( iEpoch, evalLoss[iEpoch] ))\n",
    "    \n",
    "    \n",
    "    # plotting \n",
    "    if iEpoch % displayUpdateInterval == 0:\n",
    "        \n",
    "        mod.forward( nextIterData )\n",
    "        \n",
    "        currentNN[plotCount] = mod.get_outputs()[0].asnumpy()\n",
    "\n",
    "        comboOffset = np.hstack( (xOffset + xModifier, yOffset + yModifier, zOffset + zModifier) )\n",
    "        plot += k3d.points ( np.hstack( ( batchInputs, currentNN[plotCount] * zScaling) ) + comboOffset + offset, color=0xA9A9FF, point_size = .2, shader = 'flat' )        \n",
    "        #plot += K3D.text ( str( round( evalLoss[iEpoch], 4 )), \n",
    "        #                  (comboOffset + offset + (0, 0, 3)), color=0xff00ff, size=.5, reference_point='rb')\n",
    "        \n",
    "        \n",
    "        plotCount += 1\n",
    "        if plotCount % 8 == 0:\n",
    "            xModifier = 1 * np.abs(xRange[1]-xRange[0])*1.2\n",
    "            yModifier -= 1 * np.abs(yRange[1]-yRange[0])*1.2\n",
    "        else:\n",
    "            xModifier += 1 * np.abs(xRange[1]-xRange[0])*1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(evalLoss[:], 'b')\n",
    "plt.plot(evalLoss[:], 'or')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Predictions Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = k3d.plot()\n",
    "plot += k3d.points ( np.hstack( ( batchInputs, currentNN[0]*zScaling) ), color=0xFF00FF, point_size = .3, shader = 'flat' )        \n",
    "plot += k3d.surface ( np.rot90(z,3) * zScaling, color=0x888888, xmin=np.min(xRange), xmax=np.max(xRange), ymin=np.min(yRange), ymax=np.max(yRange))\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Predictions Midway Through Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = k3d.plot()\n",
    "plot += k3d.points ( np.hstack( ( batchInputs, currentNN[int(plotCount/2)]*zScaling) ), color=0xFF00FF, point_size = .3, shader = 'flat' )        \n",
    "plot += k3d.surface ( np.rot90(z,3) * zScaling, color=0x888888, xmin=np.min(xRange), xmax=np.max(xRange), ymin=np.min(yRange), ymax=np.max(yRange))\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Predictions at End of Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = k3d.plot()\n",
    "plot += k3d.points ( np.hstack( ( batchInputs, currentNN[int(plotCount-1)]*zScaling) ), color=0xFF00FF, point_size = .3, shader = 'flat' )        \n",
    "plot += k3d.surface ( np.rot90(z,3) * zScaling, color=0x888888, xmin=np.min(xRange), xmax=np.max(xRange), ymin=np.min(yRange), ymax=np.max(yRange))\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
